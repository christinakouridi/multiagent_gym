{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMA_magym.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NQVCToZkRV8",
        "colab_type": "text"
      },
      "source": [
        "# Counterfactual Multi-agent Policy Gradients (COMA) for the ma-gym env\n",
        "Author: Christina Kouridi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBcOf9ENzRSt",
        "colab_type": "text"
      },
      "source": [
        "We will implement [Counterfactual Multi-Agent Policy Gradients (COMA)](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17193/16614) to play in the `Combat` environment from ma-gym. Please read [the wiki of ma-gym](https://github.com/koulanurag/ma-gym/wiki/) for additional information on this environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7quwWZTJlwfV",
        "colab_type": "text"
      },
      "source": [
        "## Environment overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAePzQjrcriF",
        "colab_type": "text"
      },
      "source": [
        "### Environment Description\n",
        "![Combat](https://github.com/koulanurag/ma-gym/raw/master/static/gif/Combat-v0.gif)\n",
        "\n",
        "\n",
        "Combat environment simulates a battle involving two opposing teams in a `20×20` grid. Each team consists of `m = 10` agents and their initial positions are sampled uniformly in a `5×5` square around the team center, which is picked uniformly in the grid.\n",
        "\n",
        "#### Action Space\n",
        "At each time step, an agent can perform one of the following actions:\n",
        "*   move one cell in one of four directions;\n",
        "*   attack another agent by specifying its ID `j` (there are `m` attack actions, each corresponding to one enemy agent);\n",
        "*   do nothing.\n",
        "\n",
        "#### Transition Dynamics\n",
        "If agent A attacks agent B, then B’s health point will reduce by 1, but only if B is inside the firing range of A (its surrounding `3×3` area). Agents need one-time step of cooling down after an attack, during which they cannot attack. All agents start with three health points and die when their health reaches 0. A team will win if all agents in the other team die. The simulation ends when one team wins, or neither of the teams win within 40 time steps (a draw).\n",
        "\n",
        "#### Observation Space\n",
        "When the input to a model, each agent is represented by a set of one-hot binary vectors `{i, t, l, h, c}` encoding its unique ID, team ID, location, health points, and cooldown. A model controlling an agent also sees other agents in its visual range (`3×3` surrounding area).\n",
        "\n",
        "#### Reward Settings\n",
        "The model gets a reward of -1 if the team loses or draws at the end of the game. In addition, it also get a reward of −0.1 times the total health points of the enemy team, which encourages it to attack enemy bots.\n",
        "\n",
        "#### Enemy Settings\n",
        "The model controls one team during training, and the other team consists of bots that follow a hardcoded policy. The bot policy is to attack the nearest enemy agent if it is within its firing range. If not, it approaches the nearest visible enemy agent within the visual range. An agent is visible to all bots if it is inside the visual range of any individual bot. This shared vision gives an advantage to the bot team."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bRNAhv1QMC1",
        "colab_type": "text"
      },
      "source": [
        "## Environment Set-up\n",
        "The following command will download the required scripts and set up the environment. \n",
        "\n",
        "Execute the following block until you see a WARNING and a button asking to **RESTART RUNTIME**. Click the button and wait for the runtime to restart, **then proceed to the next block of code.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0MTkFoNkLi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/ma-gym  \n",
        "!git clone https://github.com/koulanurag/ma-gym.git\n",
        "%cd /content/ma-gym \n",
        "!pip install -q -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58wskOfR5xv-",
        "colab_type": "text"
      },
      "source": [
        "Run the following block of code to continue environment set-up AFTER you have restarted the RUNTIME from the previous block.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZx9b4dS35AI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "8fb988d5-1ff1-4892-dbfd-67e4cfdde6bc"
      },
      "source": [
        "!apt-get install -y xvfb python-opengl x11-utils > /dev/null 2>&1\n",
        "!pip install pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install x11-utils\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install -U gym[atari] > /dev/null 2>&1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
            "Collecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/fa/60888a1d591db07bc9c17dce2bcfb9f00ac507c0a23ecb827e76feb8f816/setuptools-49.1.0-py3-none-any.whl (789kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 5.1MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Found existing installation: setuptools 47.3.1\n",
            "    Uninstalling setuptools-47.3.1:\n",
            "      Successfully uninstalled setuptools-47.3.1\n",
            "Successfully installed setuptools-49.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sYf6AK2d6kK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import gym\n",
        "import ma_gym\n",
        "from ma_gym.wrappers import Monitor\n",
        "from ma_gym.envs.combat.combat import Combat\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOzRdQAOu7n_",
        "colab_type": "text"
      },
      "source": [
        "#### Example of playing Combat Using Random Policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXMuXU52pznF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "970b70e9-516a-42f4-cdb2-06945c672c0a"
      },
      "source": [
        "#################################################################\n",
        "#####Here we have changed n_agents=20, n_opponents=20 to 10######\n",
        "##################Updated on 19/20/2020##########################\n",
        "env = wrap_env(Combat(grid_shape=(20, 20), n_agents=10, n_opponents=10))\n",
        "done_n = [False for _ in range(env.n_agents)]\n",
        "ep_reward = 0\n",
        "\n",
        "obs_n = env.reset()\n",
        "while not all(done_n):\n",
        "    obs_n, reward_n, done_n, info = env.step(env.action_space.sample())\n",
        "    ep_reward += sum(reward_n)\n",
        "    env.render()\n",
        "env.close()\n",
        "# To improve the training efficiency, render() is not necessary during the training.\n",
        "# We provide the render and video code here just want to demonstrate how to debugging and analysis.\n",
        "show_video()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWZIkzfEuhEE",
        "colab_type": "text"
      },
      "source": [
        "## Code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goIExNuEWSZE",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhE3SWIyV1dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import namedtuple\n",
        "import datetime as dt\n",
        "\n",
        "import gym\n",
        "import ma_gym\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LM6b8IoVNqB",
        "colab_type": "text"
      },
      "source": [
        "### Model Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTgpOys0VMWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Episode = namedtuple('Episode', ['obs', 'state', 'actions', 'actions_onehot', 'rewards', 'obs_next', \n",
        "                                 'state_next','terminated'])\n",
        "\n",
        "# most values align with those given in the original paper\n",
        "class Args:\n",
        "    def __init__(self, n_actions=None, n_agents=None, state_shape=None,\n",
        "                 obs_shape=None, seed=123, rnn_hidden_dim=64, critic_dim=128,\n",
        "                 lr_actor=.001, lr_critic=.001, epsilon=0.6, anneal_epsilon=.0003, min_epsilon=.02,\n",
        "                 td_lambda=0.9, grad_norm_clip=5.0, gamma=0.99, target_update_cycle=10,\n",
        "                 log_every=50, n_episodes=2_000, evaluate=False):\n",
        "\n",
        "        self.n_actions = n_actions\n",
        "        self.n_agents = n_agents\n",
        "        self.state_shape = state_shape\n",
        "        self.obs_shape = obs_shape\n",
        "        self.gamma = gamma\n",
        "        self.evaluate = evaluate\n",
        "\n",
        "        self.grad_norm_clip = grad_norm_clip\n",
        "\n",
        "        self.cuda = torch.cuda.is_available()\n",
        "        self.device = 'cuda' if self.cuda else 'cpu'\n",
        "\n",
        "        self.seed = seed\n",
        "\n",
        "        self.rnn_hidden_dim = rnn_hidden_dim\n",
        "        self.critic_dim = critic_dim\n",
        "        self.lr_actor = lr_actor\n",
        "        self.lr_critic = lr_critic\n",
        "\n",
        "        self.epsilon = epsilon\n",
        "        self.anneal_epsilon = anneal_epsilon\n",
        "        self.min_epsilon = min_epsilon\n",
        "\n",
        "        self.td_lambda = td_lambda\n",
        "\n",
        "        self.n_episodes = n_episodes\n",
        "        self.log_every = log_every\n",
        "        self.target_update_cycle = target_update_cycle"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o5r3SFNWA55",
        "colab_type": "text"
      },
      "source": [
        "### Critic and Actor network definitions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hh_-AVDVAkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ComaCritic(nn.Module):\n",
        "    def __init__(self, input_shape, args):\n",
        "        super(ComaCritic, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_shape, args.critic_dim)\n",
        "        self.fc2 = nn.Linear(args.critic_dim, args.critic_dim)\n",
        "        self.fc3 = nn.Linear(args.critic_dim, args.n_actions)\n",
        "\n",
        "    def forward(self, inputs: torch.tensor) -> torch.tensor:\n",
        "        # Note: using leaky RELU to mitigate vanishing gradients\n",
        "        x = F.leaky_relu(self.fc1(inputs))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        q = self.fc3(x)\n",
        "        return q\n",
        "\n",
        "class PolicyRnn(nn.Module):\n",
        "    def __init__(self, input_shape: int, args):\n",
        "        super(PolicyRnn, self).__init__()\n",
        "        self.rnn_hidden_dim = args.rnn_hidden_dim\n",
        "\n",
        "        self.fc1 = nn.Linear(input_shape, self.rnn_hidden_dim)\n",
        "        self.rnn = nn.GRUCell(self.rnn_hidden_dim, self.rnn_hidden_dim)\n",
        "        self.fc2 = nn.Linear(self.rnn_hidden_dim, args.n_actions)\n",
        "\n",
        "    def init_hidden(self) -> torch.tensor:\n",
        "        # Note zero initialisation here\n",
        "        return self.fc1.weight.new(1, self.rnn_hidden_dim).zero_()\n",
        "\n",
        "    def forward(self, obs: torch.tensor, hidden_state: torch.tensor) -> (torch.tensor, torch.tensor):\n",
        "        h_in = hidden_state.reshape(-1, self.rnn_hidden_dim)\n",
        "        x = F.leaky_relu(self.fc1(obs))\n",
        "        h = self.rnn(x, h_in)\n",
        "        q = self.fc2(h)\n",
        "        return q, h"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1IzQaujWM9e",
        "colab_type": "text"
      },
      "source": [
        "### COMA learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV4fIzQiVApE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ComaAgent:\n",
        "    def __init__(self, args):\n",
        "        self.n_actions = args.n_actions\n",
        "        self.n_agents = args.n_agents\n",
        "        self.state_shape = args.state_shape\n",
        "        self.obs_shape = args.obs_shape\n",
        "\n",
        "        self.policy = Coma(args)\n",
        "\n",
        "        self.args = args\n",
        "\n",
        "    def act(self, obs: np.ndarray, last_action: np.ndarray, agent_num: int, epsilon: float,\n",
        "            evaluate: bool = False) -> int:\n",
        "\n",
        "        # Generate actor inputs >> concatenation of observation, previous action, agent id (one hot)\n",
        "        agent_ids = np.zeros(self.n_agents)\n",
        "        agent_ids[agent_num] = 1.\n",
        "\n",
        "        inputs = np.hstack((obs, last_action, agent_ids))\n",
        "        inputs = torch.tensor(inputs, dtype=torch.float32).unsqueeze(0).to(self.args.device)\n",
        "\n",
        "        # Select hidden state for relevant agent\n",
        "        hidden_state = self.policy.eval_hidden[agent_num, :].to(self.args.device)\n",
        "\n",
        "        # Get Q values and update hidden state for agent\n",
        "        q_value, self.policy.eval_hidden[agent_num, :] = self.policy.actor.forward(inputs, hidden_state)\n",
        "        return self._sample_action(q_value.detach(), epsilon, evaluate, self.n_actions)\n",
        "\n",
        "    def train(self, episode: Episode, train_step: int, epsilon: float = None) -> float:\n",
        "        return self.policy.learn(episode=episode, train_step=train_step, epsilon=epsilon)\n",
        "\n",
        "    @staticmethod\n",
        "    def _sample_action(q_values, epsilon, evaluate, n_actions):\n",
        "        prob = torch.nn.functional.softmax(q_values, dim=-1)  # generate a probability distribution over q values\n",
        "\n",
        "        if evaluate:  # if in evaluate mode simply return the max probability\n",
        "            return torch.argmax(prob).cpu().item()\n",
        "        else:  # otherwise re-weight probabilities by mixing in a uniform distribution over n_actions equal to epsilon\n",
        "            prob = ((1 - epsilon) * prob + torch.ones_like(prob) * epsilon / n_actions)\n",
        "            return Categorical(prob).sample().cpu().item()\n",
        "\n",
        "class Coma:\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "        actor_input_shape, critic_input_shape = self._get_input_shapes(self.args)\n",
        "\n",
        "        self.actor = PolicyRnn(actor_input_shape, args).to(self.args.device)\n",
        "\n",
        "        self.online_critic = ComaCritic(critic_input_shape, self.args).to(self.args.device)\n",
        "        self.target_critic = ComaCritic(critic_input_shape, self.args).to(self.args.device)\n",
        "        self.target_critic.load_state_dict(self.online_critic.state_dict())\n",
        "\n",
        "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=args.lr_actor)\n",
        "        self.critic_optimizer = torch.optim.Adam(self.online_critic.parameters(), lr=args.lr_critic)\n",
        "\n",
        "        self.eval_hidden = None\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_input_shapes(args) -> (int, int):\n",
        "        # Actor input >> observation + previous action + agent id\n",
        "        actor_input_shape = args.obs_shape\n",
        "        actor_input_shape += args.n_actions\n",
        "        actor_input_shape += args.n_agents\n",
        "\n",
        "        # Critic input >> state + agent observation + agent id + other agents' actions + all agents' previous actions\n",
        "        critic_input_shape = args.state_shape\n",
        "        critic_input_shape += args.obs_shape\n",
        "        critic_input_shape += args.n_agents\n",
        "        critic_input_shape += args.n_actions * args.n_agents * 2\n",
        "\n",
        "        return actor_input_shape, critic_input_shape\n",
        "\n",
        "    def init_hidden(self):\n",
        "        self.eval_hidden = self.actor.init_hidden().expand(self.args.n_agents, -1)\n",
        "\n",
        "    def learn(self, episode: Episode, train_step: int, epsilon: float) -> float:\n",
        "        self.init_hidden()\n",
        "\n",
        "        q_values = self._train_critic(episode, train_step)\n",
        "        action_prob = self._get_action_prob(episode, epsilon)\n",
        "    \n",
        "        q_taken = torch.gather(q_values, dim=2, index=episode.actions).squeeze(2)\n",
        "        # get probabilities of actual actions taken\n",
        "        pi_taken = torch.gather(action_prob, dim=2, index=episode.actions).squeeze(2)\n",
        "        log_pi_taken = torch.log(pi_taken)\n",
        "\n",
        "        # counterfactual baseline\n",
        "        baseline = (q_values * action_prob).sum(dim=2, keepdim=True).squeeze(2).detach()\n",
        "        advantage = (q_taken - baseline).detach()\n",
        "\n",
        "        # policy loss using reinforce;  negative sign as we want to ascend\n",
        "        loss = - (advantage * log_pi_taken).sum()\n",
        "\n",
        "        self.actor_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.actor.parameters(), self.args.grad_norm_clip)  # clip gradients\n",
        "        self.actor_optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def _train_critic(self, episode: Episode, train_step: int):\n",
        "        # Create an actions_next tensor by concatenating the action history, offset by 1, with a zero action\n",
        "        # for the episode final timestep\n",
        "        actions_next_offset = episode.actions[1:]\n",
        "        padded_next_action = torch.zeros(*actions_next_offset[-1].shape, dtype=torch.long,\n",
        "                                         device=self.args.device).unsqueeze(0)\n",
        "        episode_actions_next = torch.cat((actions_next_offset, padded_next_action), dim=0)\n",
        "\n",
        "        q_evals, q_next_target = self._get_q_values(episode)\n",
        "        q_values = q_evals.clone()\n",
        "\n",
        "        q_evals = torch.gather(q_evals, dim=2, index=episode.actions).squeeze(2)\n",
        "        q_next_target = torch.gather(q_next_target, dim=2, index=episode_actions_next).squeeze(2)\n",
        "        targets = td_lambda_target(episode, q_next_target.cpu(), self.args).to(self.args.device)\n",
        "\n",
        "        td_error = targets.detach() - q_evals\n",
        "\n",
        "        # the value loss is a simple L2 loss\n",
        "        loss = (td_error ** 2).sum()\n",
        "\n",
        "        self.critic_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.online_critic.parameters(), self.args.grad_norm_clip)\n",
        "        self.critic_optimizer.step()\n",
        "\n",
        "        if train_step and not train_step % self.args.target_update_cycle:\n",
        "            self.target_critic.load_state_dict(self.online_critic.state_dict())\n",
        "\n",
        "        return q_values\n",
        "\n",
        "    def _get_critic_inputs(self, episode: Episode, transition_idx: int):\n",
        "        # Replicate the episode action histories for each agent\n",
        "        episode_actions_onehot_repeated = episode.actions_onehot[transition_idx].view((1, -1)).repeat(\n",
        "            self.args.n_agents, 1)\n",
        "\n",
        "        # If the first transition in the episode, create a zero action vector for the previous action\n",
        "        if transition_idx == 0:\n",
        "            episode_actions_onehot_last_repeated = torch.zeros_like(episode_actions_onehot_repeated).to(\n",
        "                self.args.device)\n",
        "        else:\n",
        "            episode_actions_onehot_last_repeated = episode.actions_onehot[transition_idx - 1].view((1, -1)).repeat(\n",
        "                self.args.n_agents, 1)\n",
        "\n",
        "        # If the last transition in the episode, then create a zero action vector\n",
        "        if transition_idx != episode.obs.shape[0] - 1:\n",
        "            episode_actions_onehot_next = episode.actions_onehot[transition_idx + 1]\n",
        "        else:\n",
        "            episode_actions_onehot_next = torch.zeros(*episode.actions_onehot[0].shape).to(self.args.device)\n",
        "\n",
        "        episode_actions_onehot_next_repeated = episode_actions_onehot_next.view((1, -1)).repeat(self.args.n_agents, 1)\n",
        "\n",
        "        episode_state_expanded = episode.state[transition_idx].unsqueeze(0).expand(self.args.n_agents, -1)\n",
        "        episode_state_next_expanded = episode.state_next[transition_idx].unsqueeze(0).expand(self.args.n_agents, -1)\n",
        "\n",
        "        # Invert identity matrix to marginalise out the current agent's actions\n",
        "        action_mask = torch.tensor(1) - torch.eye(self.args.n_agents)\n",
        "        # Note: .repeat_interleave() mirrors numpy's .repeat() behaviour (repeats elements of the tensor)\n",
        "        action_mask = action_mask.view(-1).repeat_interleave(self.args.n_actions).view(\n",
        "            self.args.n_agents, -1).to(self.args.device)\n",
        "\n",
        "        inputs, inputs_next = [], []\n",
        "\n",
        "        inputs.append(episode.obs[transition_idx])\n",
        "        inputs.append(episode_state_expanded)\n",
        "        inputs.append(episode_actions_onehot_last_repeated)\n",
        "        inputs.append(episode_actions_onehot_repeated * action_mask.unsqueeze(0))\n",
        "        inputs.append(torch.eye(self.args.n_agents).to(self.args.device))\n",
        "        inputs = torch.cat([X.reshape(self.args.n_agents, -1) for X in inputs], dim=1)\n",
        "\n",
        "        inputs_next.append(episode.obs_next[transition_idx])\n",
        "        inputs_next.append(episode_state_next_expanded)\n",
        "        inputs_next.append(episode_actions_onehot_next_repeated)\n",
        "        inputs_next.append(episode_actions_onehot_next_repeated * action_mask.unsqueeze(0))\n",
        "        inputs_next.append(torch.eye(self.args.n_agents).to(self.args.device))\n",
        "        inputs_next = torch.cat([X.reshape(self.args.n_agents, -1) for X in inputs_next], dim=1)\n",
        "\n",
        "        return inputs.to(self.args.device), inputs_next.to(self.args.device)\n",
        "\n",
        "    def _get_q_values(self, episode: Episode) -> torch.tensor:\n",
        "        q_evals, q_targets = [], []\n",
        "\n",
        "        for transition_idx in range(episode.obs.shape[0]):\n",
        "            inputs, inputs_next = self._get_critic_inputs(episode, transition_idx)\n",
        "\n",
        "            # Online net generates q values against the current state, target net against next state\n",
        "            q_eval = self.online_critic(inputs).view(self.args.n_agents, -1)\n",
        "            q_target = self.target_critic(inputs_next).view(self.args.n_agents, -1)\n",
        "\n",
        "            q_evals.append(q_eval)\n",
        "            q_targets.append(q_target)\n",
        "\n",
        "        q_evals_s = torch.stack(q_evals, dim=0)\n",
        "        q_targets_s = torch.stack(q_targets, dim=0)\n",
        "\n",
        "        return q_evals_s.to(self.args.device), q_targets_s.to(self.args.device)\n",
        "\n",
        "    def _get_actor_inputs(self, episode: Episode, transition_idx: int):\n",
        "        inputs = list()\n",
        "\n",
        "        inputs.append(episode.obs[transition_idx])\n",
        "        if transition_idx == 0:\n",
        "            inputs.append(torch.zeros_like(episode.actions_onehot[transition_idx]).to(self.args.device))\n",
        "        else:\n",
        "            inputs.append(episode.actions_onehot[transition_idx - 1])\n",
        "        inputs.append(torch.eye(self.args.n_agents).to(self.args.device))\n",
        "        return torch.cat([X.reshape(self.args.n_agents, -1) for X in inputs], dim=1)\n",
        "\n",
        "    def _get_action_prob(self, episode: Episode, epsilon: float) -> torch.tensor:\n",
        "        transitions_action_prob = []\n",
        "\n",
        "        for transition_idx in range(episode.obs.shape[0]):\n",
        "            inputs = self._get_actor_inputs(episode, transition_idx)\n",
        "            outputs, self.eval_hidden = self.actor(inputs, self.eval_hidden)\n",
        "\n",
        "            outputs = outputs.view(self.args.n_agents, -1)\n",
        "            transition_action_prob = torch.nn.functional.softmax(outputs, dim=-1)\n",
        "            transitions_action_prob.append(transition_action_prob)\n",
        "\n",
        "        transitions_action_prob_s = torch.stack(transitions_action_prob, dim=0).cpu()\n",
        "        action_probs = ((1 - epsilon) * transitions_action_prob_s) + \\\n",
        "                       torch.ones_like(transitions_action_prob_s) * epsilon / self.args.n_actions\n",
        "        return action_probs.to(self.args.device)\n",
        "\n",
        "\n",
        "def td_lambda_target(episode: Episode, q_targets: torch.tensor, args) -> torch.tensor:\n",
        "    episode_len = episode.obs.shape[0]\n",
        "\n",
        "    terminated = ~episode.terminated.repeat(1, args.n_agents).cpu()\n",
        "    reward_repeated = episode.rewards.repeat((1, args.n_agents)).cpu()  # expand central episode reward for each agent\n",
        "\n",
        "    n_step_return = torch.zeros((episode_len, args.n_agents, episode_len))\n",
        "    for transition_idx in range(episode_len-1, -1, -1):  # stepping backwards through episode\n",
        "        # First n_step_return update initialised with the q_target estimate at that timestep\n",
        "        n_step_return[transition_idx, :, 0] = reward_repeated[transition_idx] + \\\n",
        "                                              args.gamma * q_targets[transition_idx] * terminated[transition_idx]\n",
        "        for n in range(1, episode_len - transition_idx):  # and then discounts this by gamma at each preceding timestep\n",
        "            n_step_return[transition_idx, :, n] = reward_repeated[transition_idx] + \\\n",
        "                                                  args.gamma * n_step_return[transition_idx+1, :, n-1]\n",
        "\n",
        "    lambda_return = torch.zeros((episode_len, args.n_agents))\n",
        "    for transition_idx in range(episode_len):\n",
        "        returns = torch.zeros(args.n_agents)\n",
        "        for n in range(1, episode_len - transition_idx):\n",
        "            returns += args.td_lambda**(n-1) * n_step_return[transition_idx, :, n-1]\n",
        "        lambda_return[transition_idx] = (1-args.td_lambda)*returns + args.td_lambda**(episode_len-transition_idx-1) *\\\n",
        "            n_step_return[transition_idx, :, episode_len-transition_idx-1]\n",
        "    return lambda_return"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty-FIy0jZj11",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA6wmDMeVFyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ENV_NAME = 'Combat-v0'\n",
        "COMBAT_AGENTS = 10\n",
        "\n",
        "env = gym.make(ENV_NAME, grid_shape=(20, 20), n_agents=COMBAT_AGENTS, n_opponents=COMBAT_AGENTS)\n",
        "\n",
        "n_obs = env.observation_space[0].shape[0]\n",
        "n_actions = env.action_space[0].n\n",
        "n_agents = env.n_agents\n",
        "\n",
        "ARGS = Args(\n",
        "    n_agents=n_agents,\n",
        "    n_actions=n_actions,\n",
        "    state_shape=n_obs * n_agents,  # could also incorporate action history\n",
        "    obs_shape=n_obs\n",
        ")\n",
        "agents = ComaAgent(ARGS)\n",
        "\n",
        "print('\\n')\n",
        "print(f'Starting env {ENV_NAME} | Action space: {env.action_space} | Obs space: {env.observation_space}')\n",
        "print(f'Using device {\"CUDA\" if ARGS.cuda else \"CPU\"}')\n",
        "print('\\n')\n",
        "\n",
        "episode_rewards = []\n",
        "epsilon = 0 if ARGS.evaluate else ARGS.epsilon\n",
        "\n",
        "for episode_idx in range(1, ARGS.n_episodes + 1):\n",
        "    agents.policy.init_hidden()\n",
        "\n",
        "    if epsilon > ARGS.min_epsilon:\n",
        "        epsilon -= ARGS.anneal_epsilon\n",
        "\n",
        "    current_obs_n = env.reset()\n",
        "\n",
        "    done_n = [False for a in range(env.n_agents)]\n",
        "    done = all(done_n)\n",
        "\n",
        "    ep_reward = 0\n",
        "    ep_step = 0\n",
        "\n",
        "    last_actions_c = np.zeros((env.n_agents, ARGS.n_actions))\n",
        "\n",
        "    obs_h, state_h, actions_h, actions_onehot_h, rewards_h, obs_next_h, state_next_h, \\\n",
        "        terminated_h = [], [], [], [], [], [], [], []\n",
        "\n",
        "    while not done:\n",
        "        actions_c, actions_onehot_c = [], []\n",
        "\n",
        "        for agent_id in range(env.n_agents):\n",
        "            action_c = agents.act(obs=current_obs_n[agent_id], last_action=last_actions_c[agent_id],\n",
        "                                  agent_num=agent_id, epsilon=epsilon, evaluate=False)\n",
        "\n",
        "            action_onehot_c = np.zeros(env.action_space[0].n)\n",
        "            action_onehot_c[action_c] = 1\n",
        "            last_actions_c[agent_id] = action_onehot_c\n",
        "\n",
        "            actions_c.append(action_c)\n",
        "            actions_onehot_c.append(action_onehot_c)\n",
        "\n",
        "        next_obs_n, reward_n, done_n, _ = env.step(actions_c)\n",
        "\n",
        "        # if not episode_idx % ARGS.log_every:\n",
        "        #     env.render()\n",
        "\n",
        "        done = all(done_n)\n",
        "\n",
        "        state = []\n",
        "        for obs in current_obs_n:\n",
        "            state.extend(obs)\n",
        "\n",
        "        next_state = []\n",
        "        for next_obs in next_obs_n:\n",
        "            next_state.extend(next_obs)\n",
        "\n",
        "        obs_h.append(current_obs_n)\n",
        "        obs_next_h.append(next_obs_n)\n",
        "\n",
        "        state_h.append(state)\n",
        "        state_next_h.append(next_state)\n",
        "\n",
        "        actions_h.append(np.reshape(actions_c, [n_agents, 1]))\n",
        "        actions_onehot_h.append(actions_onehot_c)\n",
        "\n",
        "        rewards_h.append([sum(reward_n)])\n",
        "        terminated_h.append([done])\n",
        "\n",
        "        current_obs_n = next_obs_n\n",
        "\n",
        "        ep_reward += sum(reward_n)\n",
        "        ep_step += 1\n",
        "\n",
        "    episode = Episode(\n",
        "        obs=torch.tensor(obs_h, dtype=torch.float, device=ARGS.device),\n",
        "        state=torch.tensor(state_h, dtype=torch.float, device=ARGS.device),\n",
        "        actions=torch.tensor(actions_h, dtype=torch.long, device=ARGS.device),\n",
        "        actions_onehot=torch.tensor(actions_onehot_h, dtype=torch.float, device=ARGS.device),\n",
        "        rewards=torch.tensor(rewards_h, dtype=torch.float, device=ARGS.device),\n",
        "        obs_next=torch.tensor(obs_next_h, dtype=torch.float, device=ARGS.device),\n",
        "        state_next=torch.tensor(state_next_h, dtype=torch.float, device=ARGS.device),\n",
        "        terminated=torch.tensor(terminated_h, dtype=torch.bool, device=ARGS.device)\n",
        "    )\n",
        "\n",
        "    loss = agents.train(episode, episode_idx, epsilon=epsilon)\n",
        "\n",
        "    episode_rewards.append(ep_reward)\n",
        "\n",
        "    if not episode_idx % ARGS.log_every:\n",
        "        time.sleep(0.1)  # pause to show env final state\n",
        "        print(f'On episode {episode_idx:,d} // '\n",
        "              f'Epsilon: {epsilon:.2f} // '\n",
        "              f'Mean reward: {np.mean(episode_rewards[-ARGS.log_every:]):.1f} // '\n",
        "              f'Min reward {np.min(episode_rewards[-ARGS.log_every:]):.1f} // '\n",
        "              f'Max reward {np.max(episode_rewards[-ARGS.log_every:]):.1f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yubHxlmQusDs",
        "colab_type": "text"
      },
      "source": [
        "## Analysis on Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mOqd9j4uweF",
        "colab_type": "text"
      },
      "source": [
        "Counterfactual Multi-agent Policy Gradients (COMA) is a multi-agent actor-critic method for cooperative tasks. It uses a centralised critic to estimate the Q-function and decentralised actors to optimise the agents' policies, both of which are explicitly modelled with deep neural networks. To address the challenge of multi-agent credit assignment, it uses a novel counterfactual baseline that marginalises out a single agent's action, while keeping the other agents' actions fixed. \n",
        "\n",
        "It is expected that COMA would work well on this task due to the following reasons: \n",
        "\n",
        "*   To achieve good performance on the Combat task, cooperation among agents is required. Each agent can only attack one enemy at a time, but an agent can be attacked by more than one enemies, thus agents in the team that we are controlling need to learn to surrender and attack enemies while ideally keeping some distance from other enemies that can potentially attack them. COMA is theoretically suited for that, as it facilitates cooperation.\n",
        "\n",
        "*   COMA's counterfactual baseline results in appropriate assignment of credit to agents' actions, which facilitates learning. In typical cooperative settings, joint actions generate only global rewards, making it difficult for each agent to deduce its own contribution to the team’s success. The counterfactual baseline aims to deduce the contribution of each agent's action, and therefore encourages individual agents to sacrifice for the greater good (i.e. not running away from the enemy if there is prospect for another agent in the team to kill that enemy when surrounded). \n",
        "\n",
        "\n",
        "The following reasons may explain the suboptimal performance of our implementation:\n",
        "\n",
        "*   The COMA model works best when the global environment observation is passed to the actor, which enables agents' policies to have full observability to the environment when choosing actions. Unfortunately the Combat environment does not return the environment observation, but only a local observation for each agent which consists of a 5x5 field of view. The environment observation is  approximated by aggregating all agent observations, however this approach is very naive as the field of views overlap. This results in more myopic and suboptimal behaviour than having the full environment observation.\n",
        "\n",
        "*   Due to parameter sharing, all agents could have been processed in parallel, with each agent for each episode and time step occupying one batch entry. However, batch-learning was not used in our code, neither was a buffer from which to sample experience.\n",
        "\n",
        "*   The exploitation - exploration trade-off is challenging in environments like Combat environment that consist of many agents. A more tailed exploration strategy for multi-agent settings would result in better performance.\n",
        "\n",
        "*   As many enemies can attack one agent, but one agent can only attack on enemy, most often than not rewards are negative. Positive rewards are therefore scarce, which poses a challenge for RL whose central premise is reward maximisation. \n",
        "\n"
      ]
    }
  ]
}